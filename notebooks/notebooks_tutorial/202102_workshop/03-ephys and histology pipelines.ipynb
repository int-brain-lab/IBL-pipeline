{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through the important tables in ephys and histology schemas and introduce some useful queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datajoint and modules from ibl_pipeline\n",
    "import datajoint as dj\n",
    "from ibl_pipeline import reference, subject, acquisition, behavior\n",
    "from ibl_pipeline.analyses import behavior as behavior_analyses\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ephys` and `histology` modules contain many processing packages and are a bit slow to load. We therefore recommend accessing them with `dj.create_virtual_module()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys = dj.create_virtual_module('ephys', 'ibl_ephys')\n",
    "histology = dj.create_virtual_module('histology', 'ibl_histology')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ephys tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(ephys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the diagram, tables not represented as a class are the ones that were the leftovers during development. We will clean these tables up once in a while and you can ignore them for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of important tables:\n",
    "    \n",
    ">* ProbeModel: model of a probe, ingested from the alyx table experiments.probemodel  \n",
    ">* ProbeInsertion: ingested from the alyx table experiments.probeinsertion  \n",
    ">* ChannelGroup: raw index and local coordinates of each channel group\n",
    ">* DefaultCluster: Cluster properties achieved from the default clustering method.\n",
    ">* DefaultCluster.Metrics: metrics exported from the spike sorting softwares.\n",
    ">* DefaultCluster.Metric: same contents as Metrics, each metric is a separate entry (metric_name, metric_value), to support filtering on each of the metrics.  \n",
    ">* DefaultCluster.Ks2Label: label given by kilosort2, ‘good’ or ‘mua’\n",
    ">* GoodClusterCriterion: Criterion to identify whether a cluster is good.\n",
    ">* GoodCluster: whether a cluster is good based on the criterion defined in GoodClusterCriterion\n",
    ">* Event: Different behavioral events, including 'go cue', 'stim on', 'response', 'feedback', and 'movement'\n",
    ">* AlignedTrialSpikes: spike times of each trial aligned to different events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed table definitions could be easily checked with the method `describe()`, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`blob@ephys` refers to a blob field in external storage, but as a user, you will feel that the field is similar as an internal blob field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the contents of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histology tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(histology) + ephys.DefaultCluster + ephys.ProbeInsertion + acquisition.Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of important histology tables:\n",
    "\n",
    ">* ProbeTrajectory: the final probe trajectory with multiple users' approval, ingested from FlatIron data.\n",
    ">* ChannelBrainLocation: the final brain location assignment of each channel, ingested from FlatIron data.\n",
    ">* ClusterBrainRegion: the final brain region assignment of each cluster, based on ChannelBrainLocation data on Flatiron\n",
    "\n",
    "\n",
    "Before the final trajectory is resolved, intermediate histological results are saved in the following tables:\n",
    "\n",
    ">* Provenance: method to estimate the probe trajectory, including Ephys aligned histology track, Histology track, Micro-manipulator, and Planned  \n",
    ">* ProbeTrajectoryTemp: probe trajectory estimated with each method, ingested from Alyx table experiments.probetrajectory  \n",
    ">* ChannelBrainLocationTemp: brain coordinates and region assignment of each channel, ingested from Alyx table experiments.channel  \n",
    ">* ClusterBrainRegionTemp: Brain region assignment to each cluster  \n",
    ">* ProbeBrainRegionTemp: Brain regions assignment to each probe, including the regions of finest granularity and their upper-level areas.  \n",
    ">* DepthBrainRegionTemp: For each ProbeTrajectoryTemp, assign depth boundaries relative to the probe tip to each brain region covered by the trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select clusters from a particular session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which sessions have cluster data?\n",
    "acquisition.Session & ephys.DefaultCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the key of one of them\n",
    "key = (acquisition.Session & ephys.DefaultCluster).fetch('KEY', limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all clusters of one session\n",
    "ephys.DefaultCluster & key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch spike times, takes a little while\n",
    "clusters_spikes_times = (ephys.DefaultCluster & key).fetch('cluster_spikes_times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter clusters with particular metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three part tables of `ephys.DefaultCluster` that stores information of Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster.Metrics.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since metrics is longblob and we cannot query on the metrics.  \n",
    "Therefore, we created another table ephys.DefaultCluster.Metric to store the values of individual field of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster.Metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what are the available metric names, we could use `dj.U()`.   \n",
    "\n",
    "dj.U('field_name') is a uniform set of all possible values of a `field_name`, which is very useful to get how many unique values of a field in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.U('metric_name') & ephys.DefaultCluster.Metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [this document](https://docs.google.com/document/d/1ba_krsfm4epiAd0zbQ8hdvDN908P9VZOpTxkkH3P_ZY/edit) for the meaning of each metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter on some fields. For example, only keep clusters with firing_rate > 1 spks/sec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster & (ephys.DefaultCluster.Metric & 'metric_name=\"firing_rate\"' & 'metric_value>1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example, presence_ratio > 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.DefaultCluster & (ephys.DefaultCluster.Metric & 'metric_name=\"presence_ratio\"' & 'metric_value > 0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the distributions with certain metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize some metrics of a subset of clusters, for example, all clusters from cortexlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_cortexlab = ephys.DefaultCluster & (acquisition.Session & 'session_lab=\"cortexlab\"')\n",
    "clusters_cortexlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the values of a metric for all these clusters, for example, the \"missed_spikes_est\"\n",
    "values = (ephys.DefaultCluster.Metric & 'metric_name=\"missed_spikes_est\"').fetch('metric_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(values, bins=100);\n",
    "plt.xlabel('Missed spikes estimate');\n",
    "plt.ylabel('Cluster counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter ephys data based on behavioral performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's address a common question of how to fetch ephys data from sessions with good performance and recorded from a particular brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sessions with performance > 80% on easy trials\n",
    "good_performance_clusters = ephys.DefaultCluster & (behavior_analyses.PsychResults & 'performance_easy > 0.8')\n",
    "good_performance_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we further need to filter with brain regions, we'll need to bring in several histology related tables.\n",
    "The assignment of the brain region of each cluster is in the table `histology.ClusterBrainRegion\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histology.ClusterBrainRegion.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another table `histology.ClusterBrainRegionTemp` desribes the temporary brain region assignments for each cluster before the probe trajectory is resolved, which has a Provenance associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histology.ClusterBrainRegion & histology.Provenance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For theoreticians, we recommend just working with table `ClusterBrainRegion`, to get just the data with the probes resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's figure out the acronym of the region of your interest, for example we would like to fetch from \"frontopolar cortex\", we could do a vague search in the table `reference.BrainRegion` with the `like` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fronto_pole = reference.BrainRegion() & 'brain_region_name like \"%front%\"'\n",
    "fronto_pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict the ClusterBrainRegion with these region entries and good performance clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histology.ClusterBrainRegion & fronto_pole & good_performance_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute firing rate during a time period aligned to behavior event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's introduce another table `ephys.AlignedTrialSpikes` that might be helpful for your exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys.AlignedTrialSpikes.describe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike times of each cluster where cut into different trials, aligned to one of the following events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.U('event') & ephys.AlignedTrialSpikes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table has many many entries, so we **do not** recommend loading the whole table. Some restrictions are necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the firing rate of one cluster in a time window of 0-100ms relative to the stim on time of a trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, pick a cluster, for example, a recent ephys session from angelakilab\n",
    "clusters_recent_sessions = ephys.DefaultCluster & \\\n",
    "    (acquisition.Session & 'session_lab=\"angelakilab\"' & 'session_start_time > \"2020-08-01\"')\n",
    "clusters_recent_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then get the key of the first cluster listed above\n",
    "cluster = clusters_recent_sessions.fetch('KEY', limit=1)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch all `trial_spike_times` aligned to stim on events, compute trial number\n",
    "trials_spike_times = (ephys.AlignedTrialSpikes & cluster & 'event=\"stim on\"').fetch('trial_spike_times')\n",
    "n_trials = len(trials_spike_times)\n",
    "n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack spikes and only count the ones that are between 0 and 100. Remember that these spike times are pre-aligned\n",
    "trials_spike_times_all = np.hstack(trials_spike_times)\n",
    "spike_times_window = trials_spike_times_all[np.logical_and(trials_spike_times_all>0, trials_spike_times_all<0.1)]\n",
    "spike_times_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the total spike numbers, divided by number of trials and the time window.\n",
    "firing_rate = len(spike_times_window)/0.1/n_trials\n",
    "firing_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Rasters for a given cluster aligned to a behavior event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table `ephys.AlignedTrialSpikes` pre cut the spike times into different trials, aligned with some event. We will plot the rasters aligned to `stim on` event, using the above cluster as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_trials = ephys.AlignedTrialSpikes & cluster & 'event=\"stim on\"'\n",
    "clusters_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch, sorted by trial_id\n",
    "spk_times, trial_ids = clusters_trials.fetch(\n",
    "    'trial_spike_times', 'trial_id', order_by='trial_id')\n",
    "spk_trial_ids = np.hstack(\n",
    "    [[trial_id] * len(spk_time)\n",
    "     for trial_id, spk_time in enumerate(spk_times)])\n",
    "\n",
    "fig = plt.figure(dpi=150, frameon=False, figsize=[5, 2.5])\n",
    "ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "ax.plot(np.hstack(spk_times), spk_trial_ids, 'k.', markersize=2, alpha=0.5,\n",
    "        markeredgewidth=0)\n",
    "ax.plot([0, 0], [0, max(spk_trial_ids)], 'k')\n",
    "x_lim = [-1, 1]\n",
    "ax.set_xlim(x_lim)\n",
    "ax.set_ylim([0, max(spk_trial_ids)])\n",
    "ax.set_xlabel('Time with respect to stim on time (sec)')\n",
    "ax.set_ylabel('Trial idx')\n",
    "fig.add_axes(ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we listed a few query examples related to ephys and histology schemas that might be helpful for your research. For a full fledged introduction of major types of queries and fetches, please refer to [this notebook](01-Tools%20to%20explore%20IBL%20data%20pipeline%20with%20DataJoint.ipynb).\n",
    "\n",
    "To run the pipeline locally, we recommend using [IBL-pipeline-light](https://github.com/int-brain-lab/IBL-pipeline-light), which only contains the table accessing modules, suitable for end users that do not need to run the data processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
